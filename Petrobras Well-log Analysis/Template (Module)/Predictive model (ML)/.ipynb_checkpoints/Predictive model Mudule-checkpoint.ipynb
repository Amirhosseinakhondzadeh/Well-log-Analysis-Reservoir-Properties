{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ac8fdb",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:25px;\"> **Development of \"Machine Learning Models\"  (Workflow)**\n",
    "    \n",
    "In this Notebook, the machine learning model will be created and then the data from well-logs DLIS file [after preprocessing, sorting and finalizing the data] is loaded as input for Machine Learning model (ML); \n",
    "* Random Forest Regressor\n",
    "* Gradient Boosting Regressor\n",
    "    \n",
    "    \n",
    "For the prediction of petrophysical properties, such as porosity, permeability and water saturation, these two Regressor models **Random Forest Regressor** and **Gradient Boosting Regressor** are suitable.\n",
    "\n",
    "They are Ensemble Based Tree Methods; they are based on the generation of Decision Trees.\n",
    "\n",
    "We use Regression Models since we want to predict a continuous variable.\n",
    "\n",
    "**Advantages** of the 2 regression models, since they are based on Decision Trees:\n",
    "\n",
    "* They do not need the normalization or scaling of the original dataset;\n",
    "* They are not sensitive to outliers, thus, outliers detection and removal are not required.\n",
    "\n",
    "**==================================================================================================================**\n",
    "    \n",
    "In well-log machine learning models, the choice between regression and classification (Supervised ML) depends on the nature of the problem you are trying to solve and the type of data you have. Let's break down the reasons why regression is often preferred over classification in this context:\n",
    "\n",
    "**Continuous Output**: Well-log data often involves continuous measurements such as porosity, permeability, resistivity, and other geological properties. Regression is well-suited for predicting and modeling continuous numerical values. Classification, on the other hand, is typically used when the output is categorical or discrete, like classifying lithology or rock types.\n",
    "\n",
    "**Data Distribution**: Well-log data tends to have a wide range of continuous values. Using classification would require discretizing this data into bins or classes, which can lead to loss of information and potentially introduce biases. Regression models can capture the nuances and variations present in the continuous data more effectively.\n",
    "\n",
    "**Evaluation Metrics**: Regression models are evaluated using metrics such as mean squared error (MSE), root mean squared error (RMSE), or mean absolute error (MAE). These metrics are well-suited for measuring the accuracy of predictions involving continuous values. Classification models, on the other hand, use metrics like accuracy, precision, recall, and F1-score, which are designed for categorical predictions.\n",
    "\n",
    "**Feature Importance**: Well-log data analysis often involves understanding the relationships between different geological features and the target property. Regression models can provide insights into the quantitative impact of each feature on the predicted values, aiding in geological interpretation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2f6a2",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Importing Libraries, Regressors, and Required Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5974699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade scikit-learn==1.2.2\n",
    "%pip install --quiet qbstyles\n",
    "\n",
    "\n",
    "# Importing the dependencies\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qbstyles import mpl_style\n",
    "mpl_style(dark=False)  # Set light matplotlib style\n",
    "\n",
    "import matplotlib.patches as mpatches  # To create a legend with a color box\n",
    "import pickle\n",
    "\n",
    "# Importing the models \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "                                         \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# train_test_split is a function \n",
    "# cross_val_score and KFold are functions\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold \n",
    "\n",
    "# Regression metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# The package \"Matplotlib Inline Back-end\" provides support for Matplotlib to display figures directly inline\n",
    "# \"svg\" stands for \"scalable vector graphic\". The plot can be scaled without compromising its quality\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae917b",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Loading datafile that has been extracted from DLIS or LAS file after (Sorting, Cleaning, preprocessing, choosing the logs based on need logically ...)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c42b2f",
   "metadata": {},
   "source": [
    "Load the **csv** well log data to Pandas DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "243aff34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>GR</th>\n",
       "      <th>RHGX_HILT</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>AT10</th>\n",
       "      <th>AT20</th>\n",
       "      <th>AT30</th>\n",
       "      <th>AT60</th>\n",
       "      <th>AT90</th>\n",
       "      <th>PEFZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3241.2432</td>\n",
       "      <td>43.603180</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3241.3955</td>\n",
       "      <td>43.603180</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3241.5480</td>\n",
       "      <td>31.196218</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3241.7004</td>\n",
       "      <td>22.927324</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3241.8528</td>\n",
       "      <td>25.734980</td>\n",
       "      <td>2.832985</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>3415.1316</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.834162</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.251309</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.902054</td>\n",
       "      <td>419.289830</td>\n",
       "      <td>207.16121</td>\n",
       "      <td>3.492837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>3415.2840</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.833239</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.248991</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.493515</td>\n",
       "      <td>412.861100</td>\n",
       "      <td>209.38712</td>\n",
       "      <td>3.481267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>3415.4365</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.832363</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.247348</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.377750</td>\n",
       "      <td>416.689060</td>\n",
       "      <td>214.43398</td>\n",
       "      <td>3.470307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>3415.5889</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.831719</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.247392</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.574510</td>\n",
       "      <td>427.813420</td>\n",
       "      <td>221.12366</td>\n",
       "      <td>3.467056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>3415.7412</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.831719</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.245775</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.995930</td>\n",
       "      <td>442.204500</td>\n",
       "      <td>227.71360</td>\n",
       "      <td>3.467056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DEPTH          GR  RHGX_HILT      NPHI       AT10         AT20  \\\n",
       "0     3241.2432   43.603180   2.831039  0.011302  51.794643    61.238102   \n",
       "1     3241.3955   43.603180   2.831039  0.011302  51.794643    61.238102   \n",
       "2     3241.5480   31.196218   2.831039  0.011302  51.794643    61.238102   \n",
       "3     3241.7004   22.927324   2.831039  0.011413  51.794643    61.238102   \n",
       "4     3241.8528   25.734980   2.832985  0.011976  51.794643    61.238102   \n",
       "...         ...         ...        ...       ...        ...          ...   \n",
       "1141  3415.1316  219.444870   2.834162  0.091268   6.251309  1950.000000   \n",
       "1142  3415.2840  219.444870   2.833239  0.091268   6.248991  1950.000000   \n",
       "1143  3415.4365  219.444870   2.832363  0.091268   6.247348  1950.000000   \n",
       "1144  3415.5889  219.444870   2.831719  0.091268   6.247392  1950.000000   \n",
       "1145  3415.7412  219.444870   2.831719  0.091268   6.245775  1950.000000   \n",
       "\n",
       "            AT30        AT60       AT90      PEFZ  \n",
       "0      52.368523   47.517567   38.26941  3.912346  \n",
       "1      52.368523   47.517567   38.26941  3.912346  \n",
       "2      52.368523   47.517567   38.26941  3.912346  \n",
       "3      52.368523   47.517567   38.26941  3.912346  \n",
       "4      52.368523   47.517567   38.26941  3.912346  \n",
       "...          ...         ...        ...       ...  \n",
       "1141  101.902054  419.289830  207.16121  3.492837  \n",
       "1142  101.493515  412.861100  209.38712  3.481267  \n",
       "1143  101.377750  416.689060  214.43398  3.470307  \n",
       "1144  101.574510  427.813420  221.12366  3.467056  \n",
       "1145  101.995930  442.204500  227.71360  3.467056  \n",
       "\n",
       "[1146 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/amirhosseinakhondzadeh/CODE_WELLLOGS/Petrobras Well-log Analysis/Processed Data (out put of preprocessing == Input of ML)/df0_ML.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb5a39",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Defining Predictor (X) and what will be predicted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c8be7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"GR\",\"NPHI\"] \n",
    "X = df[predictors]\n",
    "y = df[\"PEFZ\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32c78a",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "    \n",
    "**Training & Test Well Log Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3be65ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be0dc9b",
   "metadata": {},
   "source": [
    "* **Data Splitting Function**: We utilize the \"train_test_split\" function to perform the splitting of our data.\n",
    "\n",
    "\n",
    "* **Variables to Split**: The data we're working with consists of two main variables, denoted as X and y. These are the entities that we want to partition.\n",
    "\n",
    "\n",
    "* **Training Set Size**: Instead of specifying an exact training set size, we have the option to leave it as \"None.\" In this case, the function will automatically determine the training size based on the complement of the test size. The test size is set at 20%, meaning 80% will be allocated to the training set.\n",
    "\n",
    "\n",
    "* **Test Set Size**: We assign a test size of 20%, indicating that one-fifth of the entire dataset will be allocated for testing the model's performance.\n",
    "\n",
    "\n",
    "* **Shuffling Data**: The default behavior is to shuffle the data prior to splitting. This randomization helps in creating a balanced distribution between the training and test sets.\n",
    "\n",
    "\n",
    "* **Reproducibility with Random Seed**: For the sake of reproducibility across multiple runs of the function, we introduce an integer value known as the \"random state.\" Here, we've chosen the value 42. It's essential to set this only when shuffling is enabled.\n",
    "\n",
    "\n",
    "*In essence, we're utilizing the \"train_test_split\" function to divide our data into training and test portions. We provide our data variables X and y, and the function handles the allocation. The training size is determined as the complementary value to the test size, which is set at 20%. Shuffling the data ensures randomness, and to achieve consistent outcomes in different runs, we use a random state value of 42, applying it only when shuffling is activated.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d1158f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1146, 2) (1146,) (916, 2) (230, 2) (916,) (230,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e72907",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Cross-Validation: Enhancing Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6eb0b8",
   "metadata": {},
   "source": [
    "<span style='color:black'> <span style='font-size:14px;'> **Cross-validation is a technique used to evaluate the performance of a machine learning model. It works by dividing the training dataset into k subsets, called folds. The model is then trained on k-1 folds of the training dataset and evaluated on the remaining fold. This procedure is repeated k times, with each fold being used as the validation set once. The average accuracy of the model across all k folds is then used as an estimate of the model's overall performance.**</span></span>\n",
    "\n",
    "* It is proposed to use k-fold cross-validation to evaluate the performance of two models on the training dataset. This will help them to choose the model that is most likely to generalize well to unseen data.\n",
    "\n",
    "* The k-fold cross-validation step can be skipped, since it will be carried out again during the optimization process. However, it is still a good idea to perform k-fold cross-validation on the training dataset before starting the optimization process, as this will help to ensure that the optimization process is not converging to a local optimum.\n",
    "\n",
    "Here are some additional details about k-fold cross-validation:\n",
    "\n",
    "- The value of k is typically chosen to be between 5 and 10.\n",
    "- The folds should be created randomly, to avoid any bias in the results.\n",
    "- The model should be trained and evaluated on the same set of features for each fold.\n",
    "- The accuracy of the model is typically measured using a metric such as the coefficient of determination.\n",
    "\n",
    "\n",
    "K-fold cross-validation is a powerful technique for evaluating the performance of machine learning models. It is more reliable than simply training and evaluating the model on a single holdout dataset, as it helps to mitigate the effects of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de26e9",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Creating Models + Cross-Validation [evaluation the performance of a machine learning model]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e22f61d",
   "metadata": {},
   "source": [
    "Creating Models such as **Random Forest** & **Gradient Boosting** Models\n",
    "\n",
    "using **for loop** to iterate over different models and compare them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "445b9ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of Determination for RandomForestRegressor(random_state=42) = [0.6216 0.709  0.7017 0.4652 0.6325 0.5615 0.5508 0.5754 0.698  0.5291]\n",
      "Average % Coefficient of Determination for RandomForestRegressor(random_state=42) = 60.45\n",
      "============================================\n",
      "Coefficient of Determination for GradientBoostingRegressor(random_state=42) = [0.6433 0.7415 0.6819 0.4158 0.5621 0.5719 0.5457 0.5043 0.72   0.5193]\n",
      "Average % Coefficient of Determination for GradientBoostingRegressor(random_state=42) = 59.06\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(random_state=42)  # Random Forest Model \n",
    "gb_model = GradientBoostingRegressor(random_state=42)  # Gradient Boosting Model \n",
    "\n",
    "models = [rf_model, gb_model]\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)  # Number of folds \n",
    "\n",
    "def compare_models_cv():  \n",
    "    for model in models:\n",
    "        r2_score = cross_val_score(model, X_train, y_train, cv=kf, scoring='r2')\n",
    "        r2_score = np.round(r2_score,4)\n",
    "        mean_r2 = sum(r2_score)/len(r2_score)\n",
    "        mean_r2 = mean_r2*100\n",
    "        mean_r2 = round(mean_r2,2)\n",
    "\n",
    "        print('Coefficient of Determination for', model, '=', r2_score)\n",
    "        print('Average % Coefficient of Determination for', model, '=', mean_r2)\n",
    "        print('============================================')\n",
    "        \n",
    "compare_models_cv() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5bff63",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Hyperparameter Tuning (Randomized Search CV) - Optimization Problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e2c3",
   "metadata": {},
   "source": [
    "We re-consider the training dataset and use the Randomized Search Cross Validation technique to determine **the optimal hyperparameter values** for <span style='color:blue'> <span style=\"font-size:15px;\"> the Random Forest</span> </span>\n",
    "and\n",
    "<span style='color:blue'> <span style=\"font-size:15px;\"> Gradient Boosting models </span> </span>.\n",
    "\n",
    "*To start, we define a grid of hyperparameters that will be randomly sampled when calling the RandomizedSearchCV() function. The models are then cross-validated on these random combinations of hyperparameters.*\n",
    "\n",
    "**The parameters of the RandomizedSearchCV() function are:**\n",
    "\n",
    "* The model without any hyperparameters\n",
    "* The grid of hyperparameters\n",
    "* The number of combinations to be randomly sampled (n_iter=20)\n",
    "* The number of k-folds into which the training dataset is split (cv=10)\n",
    "* The technique returns the optimal combination of hyperparameters for the two models.\n",
    "\n",
    "**Here is a more detailed explanation of each parameter:**\n",
    "\n",
    "* **Model**: The model without any hyperparameters is the base model that we will use to start the search. In this case, we are using the Random Forest and Gradient Boosting models.\n",
    "* **Grid of hyperparameters**: The grid of hyperparameters defines the range of values that we will randomly sample from. This allows us to explore a wider range of hyperparameter values than if we were to simply grid search over a fixed set of values.\n",
    "* **Number of combinations to be randomly sampled (n_iter=20)**: The n_iter parameter specifies the number of random combinations of hyperparameters to be sampled. In this case, we are sampling 20 combinations.\n",
    "* **Number of k-folds into which the training dataset is split (cv=10)**: The cv parameter specifies the number of k-folds to use for cross-validation. In this case, we are using 10 folds.\n",
    "* The RandomizedSearchCV() function will randomly sample 20 combinations of hyperparameters from the grid and cross-validate each combination on 10 folds of the training dataset. The function will then return the combination of hyperparameters that resulted in the best cross-validation score.\n",
    "\n",
    "This technique allows us to quickly and efficiently explore a wide range of hyperparameter values to find the optimal combination for our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86c4a9",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:15px;\"> \n",
    "**Random Forest Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c11d9",
   "metadata": {},
   "source": [
    "We consider the following hyperparameters:\n",
    "\n",
    "* n_estimators = number of trees in the forest;\n",
    "* max_depth = the maximum depth of the tree;\n",
    "* criterion = the function that measures the quality of the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "101eb387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST Hyperparameters\n",
    "\n",
    "# Number of trees to be used\n",
    "rf_n_estimators = [100, 150, 200, 250, 300, 350, 400]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "rf_max_depth = [5, 10, 15, 20, 25]\n",
    "\n",
    "# Criterion to split on\n",
    "rf_criterion = ['squared_error']                         # \"squared_error\" is by default. It is optional\n",
    "\n",
    "# Create the grid \n",
    "rf_grid = {'n_estimators': rf_n_estimators,\n",
    "           'max_depth': rf_max_depth,\n",
    "           'criterion': rf_criterion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9834923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [5, 10, 15, 20, 25],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 150, 200, 250,\n",
       "                                                         300, 350, 400]},\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [5, 10, 15, 20, 25],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 150, 200, 250,\n",
       "                                                         300, 350, 400]},\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'criterion': ['squared_error'],\n",
       "                                        'max_depth': [5, 10, 15, 20, 25],\n",
       "                                        'n_estimators': [100, 150, 200, 250,\n",
       "                                                         300, 350, 400]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model to be tuned \n",
    "rf_model = RandomForestRegressor(random_state=42)        # Shuffle=True by default\n",
    "\n",
    "# Create the random search Random Forest \n",
    "rf_random = RandomizedSearchCV(rf_model, rf_grid, n_iter=20, cv=10, random_state=42)\n",
    "\n",
    "# Fit the random search model \n",
    "rf_random.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10ea6d0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.58885643, 0.56909473, 0.41963794, 0.16617167, 0.2424422 ,\n",
       "        0.25683694, 0.56711476, 0.4986397 , 0.21407225, 0.32304287,\n",
       "        0.28638771, 0.58381152, 0.11730025, 0.34924774, 0.40415077,\n",
       "        0.66506228, 0.40444431, 0.43023741, 0.17594767, 0.23366919]),\n",
       " 'std_fit_time': array([0.01190323, 0.00262206, 0.01023218, 0.00106005, 0.00097819,\n",
       "        0.01992609, 0.00791665, 0.00243257, 0.00079913, 0.00160324,\n",
       "        0.00173297, 0.006448  , 0.00039869, 0.00138113, 0.00114193,\n",
       "        0.0082836 , 0.00160679, 0.00531822, 0.00504721, 0.00605522]),\n",
       " 'mean_score_time': array([0.02482176, 0.02482221, 0.01803899, 0.00742693, 0.01051645,\n",
       "        0.01114318, 0.02328713, 0.02190804, 0.00986583, 0.01395547,\n",
       "        0.01296782, 0.02429924, 0.00654097, 0.01754129, 0.0170161 ,\n",
       "        0.02692366, 0.02000186, 0.01898487, 0.00935669, 0.01199079]),\n",
       " 'std_score_time': array([1.35817616e-03, 3.21569315e-04, 1.40079644e-03, 7.97334468e-05,\n",
       "        1.60144033e-04, 4.26167184e-04, 3.02049600e-04, 3.14582578e-04,\n",
       "        6.14073005e-05, 9.09339914e-04, 1.80614655e-04, 1.55116770e-03,\n",
       "        2.31120467e-05, 1.24537335e-04, 1.59147502e-04, 4.34528231e-04,\n",
       "        1.59970141e-04, 3.29882205e-04, 6.55134160e-04, 4.13850881e-04]),\n",
       " 'param_n_estimators': masked_array(data=[350, 400, 250, 100, 150, 150, 350, 350, 150, 200, 200,\n",
       "                    350, 100, 300, 250, 400, 350, 300, 150, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[20, 10, 20, 20, 15, 25, 15, 10, 10, 15, 10, 25, 5, 5,\n",
       "                    15, 20, 5, 10, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 350,\n",
       "   'max_depth': 20,\n",
       "   'criterion': 'squared_error'},\n",
       "  {'n_estimators': 400, 'max_depth': 10, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 250, 'max_depth': 20, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 100, 'max_depth': 20, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 150, 'max_depth': 15, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 150, 'max_depth': 25, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 350, 'max_depth': 15, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 350, 'max_depth': 10, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 150, 'max_depth': 10, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 200, 'max_depth': 15, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 200, 'max_depth': 10, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 350, 'max_depth': 25, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 100, 'max_depth': 5, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 300, 'max_depth': 5, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 250, 'max_depth': 15, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 400, 'max_depth': 20, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 350, 'max_depth': 5, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 300, 'max_depth': 10, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 150, 'max_depth': 5, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 200, 'max_depth': 5, 'criterion': 'squared_error'}],\n",
       " 'split0_test_score': array([0.24158906, 0.26135035, 0.2485908 , 0.24879728, 0.24824529,\n",
       "        0.24502532, 0.24469537, 0.26594621, 0.27627463, 0.25110377,\n",
       "        0.27824885, 0.24107713, 0.36180345, 0.36104895, 0.25203345,\n",
       "        0.23635743, 0.36010607, 0.27118635, 0.35989455, 0.36145912]),\n",
       " 'split1_test_score': array([0.5954309 , 0.60664342, 0.58595091, 0.58082726, 0.59181105,\n",
       "        0.59276229, 0.5962174 , 0.60337335, 0.60251511, 0.58878676,\n",
       "        0.59802301, 0.59534743, 0.55738502, 0.56350165, 0.58617675,\n",
       "        0.59896754, 0.56113831, 0.6024267 , 0.55825658, 0.55455346]),\n",
       " 'split2_test_score': array([0.48385869, 0.50433857, 0.4738281 , 0.46910253, 0.46849813,\n",
       "        0.4662613 , 0.48647368, 0.50619019, 0.48408449, 0.46647685,\n",
       "        0.48150729, 0.48399585, 0.53175497, 0.55558523, 0.47645155,\n",
       "        0.48056387, 0.56247716, 0.49511163, 0.53857333, 0.53855123]),\n",
       " 'split3_test_score': array([0.7539589 , 0.7665993 , 0.75500282, 0.75096574, 0.74737101,\n",
       "        0.7487    , 0.75491856, 0.76554214, 0.75674764, 0.74980863,\n",
       "        0.76122183, 0.75416357, 0.73541528, 0.74168508, 0.7547575 ,\n",
       "        0.75427906, 0.74094865, 0.76636686, 0.72964727, 0.73434567]),\n",
       " 'split4_test_score': array([0.7280233 , 0.73170019, 0.72872614, 0.72373147, 0.72477102,\n",
       "        0.72474163, 0.72995072, 0.73050373, 0.72328887, 0.72979192,\n",
       "        0.73014221, 0.72823849, 0.70671277, 0.7046647 , 0.73081463,\n",
       "        0.72898298, 0.70575614, 0.73034142, 0.70075   , 0.7028111 ]),\n",
       " 'split5_test_score': array([0.64533575, 0.65537837, 0.6411404 , 0.64552258, 0.64520834,\n",
       "        0.64560931, 0.64565842, 0.655346  , 0.65618147, 0.63788432,\n",
       "        0.64887001, 0.64557205, 0.66356204, 0.66488625, 0.64041459,\n",
       "        0.64494123, 0.6640556 , 0.65429704, 0.66632129, 0.66405254]),\n",
       " 'split6_test_score': array([0.47753825, 0.48546522, 0.48190434, 0.44741945, 0.48051581,\n",
       "        0.4778707 , 0.48132983, 0.48371342, 0.48679968, 0.48943995,\n",
       "        0.49541875, 0.47772068, 0.47025766, 0.47070514, 0.4852563 ,\n",
       "        0.4777486 , 0.47278117, 0.483183  , 0.47322731, 0.47443821]),\n",
       " 'split7_test_score': array([0.64229982, 0.63162859, 0.64984148, 0.65833045, 0.6436982 ,\n",
       "        0.64586499, 0.64251877, 0.63399847, 0.63669587, 0.64277358,\n",
       "        0.63494495, 0.64222748, 0.58736636, 0.58578425, 0.6494311 ,\n",
       "        0.6393101 , 0.58190029, 0.63605246, 0.57997993, 0.58164279]),\n",
       " 'split8_test_score': array([0.7614106 , 0.77484136, 0.75932141, 0.74941643, 0.754856  ,\n",
       "        0.75176878, 0.76311123, 0.77650841, 0.77059624, 0.75734787,\n",
       "        0.7751405 , 0.76173701, 0.77853573, 0.77969663, 0.76095671,\n",
       "        0.76002362, 0.77931199, 0.7764534 , 0.77742131, 0.77827792]),\n",
       " 'split9_test_score': array([0.57342229, 0.5756088 , 0.57392534, 0.5823176 , 0.58705118,\n",
       "        0.58431144, 0.57563771, 0.57895076, 0.58705243, 0.58373921,\n",
       "        0.58717997, 0.574094  , 0.60231608, 0.60532639, 0.57560739,\n",
       "        0.57066275, 0.60080859, 0.58196968, 0.60283235, 0.60686468]),\n",
       " 'mean_test_score': array([0.59028676, 0.59935542, 0.58982317, 0.58564308, 0.5892026 ,\n",
       "        0.58829157, 0.59205117, 0.60000727, 0.59802364, 0.58971529,\n",
       "        0.59906974, 0.59041737, 0.59951094, 0.60328843, 0.59119   ,\n",
       "        0.58918372, 0.6029284 , 0.59973885, 0.59869039, 0.59969967]),\n",
       " 'std_test_score': array([0.15057196, 0.14741938, 0.14944974, 0.15108856, 0.14818543,\n",
       "        0.14920657, 0.14985759, 0.14634854, 0.14302438, 0.14779197,\n",
       "        0.14348319, 0.15074471, 0.12076702, 0.12032138, 0.14851504,\n",
       "        0.15190435, 0.12008381, 0.14599557, 0.11935878, 0.11974836]),\n",
       " 'rank_test_score': array([14,  7, 15, 20, 17, 19, 11,  3, 10, 16,  8, 13,  6,  1, 12, 18,  2,\n",
       "         4,  9,  5], dtype=int32)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the results \n",
    "rf_random.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf94b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641e5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a6c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d819e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b5a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac343ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6bd331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6634d575",
   "metadata": {},
   "source": [
    "<span style='color:blue'> <span style=\"font-size:15px;\"> the Random Forest</span> </span>\n",
    "and\n",
    "<span style='color:blue'> <span style=\"font-size:15px;\"> Gradient Boosting models </span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5227f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb437c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95e790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
