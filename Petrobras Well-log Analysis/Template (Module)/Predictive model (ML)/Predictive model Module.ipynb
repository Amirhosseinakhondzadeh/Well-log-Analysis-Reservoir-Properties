{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ac8fdb",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:25px;\"> **Development of \"Machine Learning Models\"  (Workflow)**\n",
    "    \n",
    "In this Notebook, the machine learning model will be created and then the data from well-logs DLIS file [after preprocessing, sorting and finalizing the data] is loaded as input for Machine Learning model (ML); \n",
    "* Random Forest Regressor\n",
    "* Gradient Boosting Regressor\n",
    "    \n",
    "    \n",
    "For the prediction of petrophysical properties, such as porosity, permeability and water saturation, these two Regressor models **Random Forest Regressor** and **Gradient Boosting Regressor** are suitable.\n",
    "\n",
    "They are Ensemble Based Tree Methods; they are based on the generation of Decision Trees.\n",
    "\n",
    "We use Regression Models since we want to predict a continuous variable.\n",
    "\n",
    "**Advantages** of the 2 regression models, since they are based on Decision Trees:\n",
    "\n",
    "* They do not need the normalization or scaling of the original dataset;\n",
    "* They are not sensitive to outliers, thus, outliers detection and removal are not required.\n",
    "\n",
    "**==================================================================================================================**\n",
    "    \n",
    "In well-log machine learning models, the choice between regression and classification (Supervised ML) depends on the nature of the problem you are trying to solve and the type of data you have. Let's break down the reasons why regression is often preferred over classification in this context:\n",
    "\n",
    "**Continuous Output**: Well-log data often involves continuous measurements such as porosity, permeability, resistivity, and other geological properties. Regression is well-suited for predicting and modeling continuous numerical values. Classification, on the other hand, is typically used when the output is categorical or discrete, like classifying lithology or rock types.\n",
    "\n",
    "**Data Distribution**: Well-log data tends to have a wide range of continuous values. Using classification would require discretizing this data into bins or classes, which can lead to loss of information and potentially introduce biases. Regression models can capture the nuances and variations present in the continuous data more effectively.\n",
    "\n",
    "**Evaluation Metrics**: Regression models are evaluated using metrics such as mean squared error (MSE), root mean squared error (RMSE), or mean absolute error (MAE). These metrics are well-suited for measuring the accuracy of predictions involving continuous values. Classification models, on the other hand, use metrics like accuracy, precision, recall, and F1-score, which are designed for categorical predictions.\n",
    "\n",
    "**Feature Importance**: Well-log data analysis often involves understanding the relationships between different geological features and the target property. Regression models can provide insights into the quantitative impact of each feature on the predicted values, aiding in geological interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2f6a2",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Importing Libraries, Regressors, and Required Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5974699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade scikit-learn==1.2.2\n",
    "%pip install --quiet qbstyles\n",
    "\n",
    "\n",
    "# Importing the dependencies\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qbstyles import mpl_style\n",
    "mpl_style(dark=False)  # Set light matplotlib style\n",
    "\n",
    "import matplotlib.patches as mpatches  # To create a legend with a color box\n",
    "import pickle\n",
    "\n",
    "# Importing the models \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "                                         \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# train_test_split is a function \n",
    "# cross_val_score and KFold are functions\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold \n",
    "\n",
    "# Regression metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# The package \"Matplotlib Inline Back-end\" provides support for Matplotlib to display figures directly inline\n",
    "# \"svg\" stands for \"scalable vector graphic\". The plot can be scaled without compromising its quality\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae917b",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Loading datafile that has been extracted from DLIS or LAS file after (Sorting, Cleaning, preprocessing, choosing the logs based on need logically ...)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c42b2f",
   "metadata": {},
   "source": [
    "Load the **csv** well log data to Pandas DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243aff34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>GR</th>\n",
       "      <th>RHGX_HILT</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>AT10</th>\n",
       "      <th>AT20</th>\n",
       "      <th>AT30</th>\n",
       "      <th>AT60</th>\n",
       "      <th>AT90</th>\n",
       "      <th>PEFZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3241.2432</td>\n",
       "      <td>43.603180</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3241.3955</td>\n",
       "      <td>43.603180</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3241.5480</td>\n",
       "      <td>31.196218</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3241.7004</td>\n",
       "      <td>22.927324</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3241.8528</td>\n",
       "      <td>25.734980</td>\n",
       "      <td>2.832985</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>3415.1316</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.834162</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.251309</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.902054</td>\n",
       "      <td>419.289830</td>\n",
       "      <td>207.16121</td>\n",
       "      <td>3.492837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>3415.2840</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.833239</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.248991</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.493515</td>\n",
       "      <td>412.861100</td>\n",
       "      <td>209.38712</td>\n",
       "      <td>3.481267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>3415.4365</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.832363</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.247348</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.377750</td>\n",
       "      <td>416.689060</td>\n",
       "      <td>214.43398</td>\n",
       "      <td>3.470307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>3415.5889</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.831719</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.247392</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.574510</td>\n",
       "      <td>427.813420</td>\n",
       "      <td>221.12366</td>\n",
       "      <td>3.467056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>3415.7412</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.831719</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.245775</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.995930</td>\n",
       "      <td>442.204500</td>\n",
       "      <td>227.71360</td>\n",
       "      <td>3.467056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DEPTH          GR  RHGX_HILT      NPHI       AT10         AT20  \\\n",
       "0     3241.2432   43.603180   2.831039  0.011302  51.794643    61.238102   \n",
       "1     3241.3955   43.603180   2.831039  0.011302  51.794643    61.238102   \n",
       "2     3241.5480   31.196218   2.831039  0.011302  51.794643    61.238102   \n",
       "3     3241.7004   22.927324   2.831039  0.011413  51.794643    61.238102   \n",
       "4     3241.8528   25.734980   2.832985  0.011976  51.794643    61.238102   \n",
       "...         ...         ...        ...       ...        ...          ...   \n",
       "1141  3415.1316  219.444870   2.834162  0.091268   6.251309  1950.000000   \n",
       "1142  3415.2840  219.444870   2.833239  0.091268   6.248991  1950.000000   \n",
       "1143  3415.4365  219.444870   2.832363  0.091268   6.247348  1950.000000   \n",
       "1144  3415.5889  219.444870   2.831719  0.091268   6.247392  1950.000000   \n",
       "1145  3415.7412  219.444870   2.831719  0.091268   6.245775  1950.000000   \n",
       "\n",
       "            AT30        AT60       AT90      PEFZ  \n",
       "0      52.368523   47.517567   38.26941  3.912346  \n",
       "1      52.368523   47.517567   38.26941  3.912346  \n",
       "2      52.368523   47.517567   38.26941  3.912346  \n",
       "3      52.368523   47.517567   38.26941  3.912346  \n",
       "4      52.368523   47.517567   38.26941  3.912346  \n",
       "...          ...         ...        ...       ...  \n",
       "1141  101.902054  419.289830  207.16121  3.492837  \n",
       "1142  101.493515  412.861100  209.38712  3.481267  \n",
       "1143  101.377750  416.689060  214.43398  3.470307  \n",
       "1144  101.574510  427.813420  221.12366  3.467056  \n",
       "1145  101.995930  442.204500  227.71360  3.467056  \n",
       "\n",
       "[1146 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/amirhosseinakhondzadeh/CODE_WELLLOGS/Petrobras Well-log Analysis/Processed Data (out put of preprocessing == Input of ML)/df0_ML.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb5a39",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Defining Predictor (X) and what will be predicted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8be7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"GR\",\"NPHI\"] \n",
    "X = df[predictors]\n",
    "y = df[\"PEFZ\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32c78a",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "    \n",
    "**Training & Test Well Log Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be65ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be0dc9b",
   "metadata": {},
   "source": [
    "* **Data Splitting Function**: We utilize the \"train_test_split\" function to perform the splitting of our data.\n",
    "\n",
    "\n",
    "* **Variables to Split**: The data we're working with consists of two main variables, denoted as X and y. These are the entities that we want to partition.\n",
    "\n",
    "\n",
    "* **Training Set Size**: Instead of specifying an exact training set size, we have the option to leave it as \"None.\" In this case, the function will automatically determine the training size based on the complement of the test size. The test size is set at 20%, meaning 80% will be allocated to the training set.\n",
    "\n",
    "\n",
    "* **Test Set Size**: We assign a test size of 20%, indicating that one-fifth of the entire dataset will be allocated for testing the model's performance.\n",
    "\n",
    "\n",
    "* **Shuffling Data**: The default behavior is to shuffle the data prior to splitting. This randomization helps in creating a balanced distribution between the training and test sets.\n",
    "\n",
    "\n",
    "* **Reproducibility with Random Seed**: For the sake of reproducibility across multiple runs of the function, we introduce an integer value known as the \"random state.\" Here, we've chosen the value 42. It's essential to set this only when shuffling is enabled.\n",
    "\n",
    "\n",
    "*In essence, we're utilizing the \"train_test_split\" function to divide our data into training and test portions. We provide our data variables X and y, and the function handles the allocation. The training size is determined as the complementary value to the test size, which is set at 20%. Shuffling the data ensures randomness, and to achieve consistent outcomes in different runs, we use a random state value of 42, applying it only when shuffling is activated.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d1158f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1146, 2) (1146,) (916, 2) (230, 2) (916,) (230,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e72907",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Cross-Validation: Enhancing Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6eb0b8",
   "metadata": {},
   "source": [
    "<span style='color:black'> <span style='font-size:14px;'> **Cross-validation is a technique used to evaluate the performance of a machine learning model. It works by dividing the training dataset into k subsets, called folds. The model is then trained on k-1 folds of the training dataset and evaluated on the remaining fold. This procedure is repeated k times, with each fold being used as the validation set once. The average accuracy of the model across all k folds is then used as an estimate of the model's overall performance.**</span></span>\n",
    "\n",
    "* It is proposed to use k-fold cross-validation to evaluate the performance of two models on the training dataset. This will help them to choose the model that is most likely to generalize well to unseen data.\n",
    "\n",
    "* The k-fold cross-validation step can be skipped, since it will be carried out again during the optimization process. However, it is still a good idea to perform k-fold cross-validation on the training dataset before starting the optimization process, as this will help to ensure that the optimization process is not converging to a local optimum.\n",
    "\n",
    "Here are some additional details about k-fold cross-validation:\n",
    "\n",
    "- The value of k is typically chosen to be between 5 and 10.\n",
    "- The folds should be created randomly, to avoid any bias in the results.\n",
    "- The model should be trained and evaluated on the same set of features for each fold.\n",
    "- The accuracy of the model is typically measured using a metric such as the coefficient of determination.\n",
    "\n",
    "\n",
    "K-fold cross-validation is a powerful technique for evaluating the performance of machine learning models. It is more reliable than simply training and evaluating the model on a single holdout dataset, as it helps to mitigate the effects of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de26e9",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Creating Models + Cross-Validation [evaluation the performance of a machine learning model]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e22f61d",
   "metadata": {},
   "source": [
    "Creating Models such as **Random Forest** & **Gradient Boosting** Models\n",
    "\n",
    "using **for loop** to iterate over different models and compare them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445b9ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of Determination for RandomForestRegressor(random_state=42) = [0.6216 0.709  0.7017 0.4652 0.6325 0.5615 0.5508 0.5754 0.698  0.5291]\n",
      "Average % Coefficient of Determination for RandomForestRegressor(random_state=42) = 60.45\n",
      "============================================\n",
      "Coefficient of Determination for GradientBoostingRegressor(random_state=42) = [0.6433 0.7415 0.6819 0.4158 0.5621 0.5719 0.5457 0.5043 0.72   0.5193]\n",
      "Average % Coefficient of Determination for GradientBoostingRegressor(random_state=42) = 59.06\n",
      "============================================\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(random_state=42)  # Random Forest Model \n",
    "gb_model = GradientBoostingRegressor(random_state=42)  # Gradient Boosting Model \n",
    "\n",
    "models = [rf_model, gb_model]\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)  # Number of folds \n",
    "\n",
    "def compare_models_cv():  \n",
    "    for model in models:\n",
    "        r2_score = cross_val_score(model, X_train, y_train, cv=kf, scoring='r2')\n",
    "        r2_score = np.round(r2_score,4)\n",
    "        mean_r2 = sum(r2_score)/len(r2_score)\n",
    "        mean_r2 = mean_r2*100\n",
    "        mean_r2 = round(mean_r2,2)\n",
    "\n",
    "        print('Coefficient of Determination for', model, '=', r2_score)\n",
    "        print('Average % Coefficient of Determination for', model, '=', mean_r2)\n",
    "        print('============================================')\n",
    "        \n",
    "compare_models_cv() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5bff63",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Hyperparameter Tuning (Randomized Search CV) - Optimization Problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e2c3",
   "metadata": {},
   "source": [
    "We re-consider the training dataset and use the Randomized Search Cross Validation technique to determine **the optimal hyperparameter values** for <span style='color:blue'> <span style=\"font-size:15px;\"> the Random Forest</span> </span>\n",
    "and\n",
    "<span style='color:blue'> <span style=\"font-size:15px;\"> Gradient Boosting models </span> </span>.\n",
    "\n",
    "*To start, we define a grid of hyperparameters that will be randomly sampled when calling the RandomizedSearchCV() function. The models are then cross-validated on these random combinations of hyperparameters.*\n",
    "\n",
    "**The parameters of the RandomizedSearchCV() function are:**\n",
    "\n",
    "* The model without any hyperparameters\n",
    "* The grid of hyperparameters\n",
    "* The number of combinations to be randomly sampled (n_iter=20)\n",
    "* The number of k-folds into which the training dataset is split (cv=10)\n",
    "* The technique returns the optimal combination of hyperparameters for the two models.\n",
    "\n",
    "**Here is a more detailed explanation of each parameter:**\n",
    "\n",
    "* **Model**: The model without any hyperparameters is the base model that we will use to start the search. In this case, we are using the Random Forest and Gradient Boosting models.\n",
    "* **Grid of hyperparameters**: The grid of hyperparameters defines the range of values that we will randomly sample from. This allows us to explore a wider range of hyperparameter values than if we were to simply grid search over a fixed set of values.\n",
    "* **Number of combinations to be randomly sampled (n_iter=20)**: The n_iter parameter specifies the number of random combinations of hyperparameters to be sampled. In this case, we are sampling 20 combinations.\n",
    "* **Number of k-folds into which the training dataset is split (cv=10)**: The cv parameter specifies the number of k-folds to use for cross-validation. In this case, we are using 10 folds.\n",
    "* The RandomizedSearchCV() function will randomly sample 20 combinations of hyperparameters from the grid and cross-validate each combination on 10 folds of the training dataset. The function will then return the combination of hyperparameters that resulted in the best cross-validation score.\n",
    "\n",
    "This technique allows us to quickly and efficiently explore a wide range of hyperparameter values to find the optimal combination for our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86c4a9",
   "metadata": {},
   "source": [
    "<span style='color:red'> <span style=\"font-size:15px;\"> \n",
    "**Random Forest Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c11d9",
   "metadata": {},
   "source": [
    "We consider the following **hyperparameters**:\n",
    "\n",
    "* n_estimators = number of trees in the forest; **(Number of trees to be used)**\n",
    "* max_depth = the maximum depth of the tree; **(Maximum number of levels in tree)**\n",
    "* criterion = the function that measures the quality of the split; **(Criterion to split on)**\n",
    "\n",
    "<span style='color:blue'> <span style=\"font-size:15px;\"> **then Grid Creation**:</span> </span>  grid of Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101eb387",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_n_estimators = [100, 150, 200, 250, 300, 350, 400]\n",
    "rf_max_depth = [5, 10, 15, 20, 25]\n",
    "rf_criterion = ['squared_error']                         # \"squared_error\" is by default. It is optional\n",
    "\n",
    "rf_grid = {'n_estimators': rf_n_estimators, 'max_depth': rf_max_depth, 'criterion': rf_criterion}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3885fe",
   "metadata": {},
   "source": [
    "In the line below:\n",
    "\n",
    "the RandomizedSearchCV class in scikit-learn is used **to tune the hyperparameters of a RandomForestRegressor model**.\n",
    "\n",
    "* The first line of code creates a **RandomForestRegressor model** with a random state of 42. This ensures that the results of the model are reproducible.\n",
    "\n",
    "\n",
    "* The second line of code creates a **RandomizedSearchCV object**. This object will be used to search for the best hyperparameters for the RandomForestRegressor model.\n",
    "\n",
    "\n",
    "<span style='color:blue'> <span style=\"font-size:15px;\">**rf_model**</span> </span>:\n",
    "The model to be tuned. In this case, it is a RandomForestRegressor model.\n",
    "\n",
    "<span style='color:blue'> <span style=\"font-size:15px;\">**rf_grid**</span> </span>: \n",
    "A dictionary of hyperparameters to search. The keys of the dictionary are the hyperparameter names, and the values are the possible values to search for. In this case, the dictionary is searching for the best values of the n_estimators and max_depth hyperparameters.\n",
    "\n",
    "<span style='color:blue'> <span style=\"font-size:15px;\">**n_iter**</span> </span>:\n",
    "The number of hyperparameter combinations to try. In this case, the RandomizedSearchCV object will try 20 different combinations of hyperparameters.\n",
    "\n",
    "<span style='color:blue'> <span style=\"font-size:15px;\">**cv**</span> </span>:\n",
    "The number of folds to use for cross-validation. In this case, the RandomizedSearchCV object will use 10 folds for cross-validation.\n",
    "\n",
    "<span style='color:blue'> <span style=\"font-size:15px;\">**random_state**</span> </span>:\n",
    "The random state to use for the search. In this case, the random state is set to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9834923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [5, 10, 15, 20, 25],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 150, 200, 250,\n",
       "                                                         300, 350, 400]},\n",
       "                   random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [5, 10, 15, 20, 25],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 150, 200, 250,\n",
       "                                                         300, 350, 400]},\n",
       "                   random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(random_state=42),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'criterion': ['squared_error'],\n",
       "                                        'max_depth': [5, 10, 15, 20, 25],\n",
       "                                        'n_estimators': [100, 150, 200, 250,\n",
       "                                                         300, 350, 400]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(random_state=42)        # Shuffle=True by default\n",
    "\n",
    "rf_random = RandomizedSearchCV(rf_model, rf_grid, n_iter=20, cv=10, random_state=42)\n",
    "\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ea6d0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.57844732, 0.57145364, 0.42021604, 0.16675055, 0.24206901,\n",
       "        0.24825983, 0.56266639, 0.49961836, 0.21404765, 0.32124128,\n",
       "        0.28432901, 0.58360012, 0.11554503, 0.34544241, 0.40203595,\n",
       "        0.6572217 , 0.40663614, 0.42638006, 0.1754765 , 0.23194132]),\n",
       " 'std_fit_time': array([0.00414218, 0.00605534, 0.01125167, 0.00152174, 0.0024636 ,\n",
       "        0.00119596, 0.00292103, 0.00892965, 0.00149809, 0.00286689,\n",
       "        0.0018157 , 0.01224747, 0.00067212, 0.00338455, 0.00237903,\n",
       "        0.0033127 , 0.01072229, 0.00292729, 0.00415772, 0.00149106]),\n",
       " 'mean_score_time': array([0.02336271, 0.02477155, 0.01756394, 0.00756934, 0.01041541,\n",
       "        0.01059754, 0.02311478, 0.02199676, 0.0098233 , 0.01343198,\n",
       "        0.01278563, 0.02397602, 0.00643823, 0.01690478, 0.016594  ,\n",
       "        0.0264854 , 0.01967926, 0.01871829, 0.009073  , 0.01177993]),\n",
       " 'std_score_time': array([0.0002336 , 0.00056496, 0.0012329 , 0.00039915, 0.00026764,\n",
       "        0.00011665, 0.00021786, 0.00167002, 0.00017537, 0.00016345,\n",
       "        0.00031665, 0.00161651, 0.00027898, 0.00025628, 0.00033887,\n",
       "        0.00043832, 0.00036237, 0.00055371, 0.00014396, 0.00015985]),\n",
       " 'param_n_estimators': masked_array(data=[350, 400, 250, 100, 150, 150, 350, 350, 150, 200, 200,\n",
       "                    350, 100, 300, 250, 400, 350, 300, 150, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[20, 10, 20, 20, 15, 25, 15, 10, 10, 15, 10, 25, 5, 5,\n",
       "                    15, 20, 5, 10, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error', 'squared_error',\n",
       "                    'squared_error', 'squared_error'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_estimators': 350,\n",
       "   'max_depth': 20,\n",
       "   'criterion': 'squared_error'},\n",
       "  {'n_estimators': 400, 'max_depth': 10, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 250, 'max_depth': 20, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 100, 'max_depth': 20, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 150, 'max_depth': 15, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 150, 'max_depth': 25, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 350, 'max_depth': 15, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 350, 'max_depth': 10, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 150, 'max_depth': 10, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 200, 'max_depth': 15, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 200, 'max_depth': 10, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 350, 'max_depth': 25, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 100, 'max_depth': 5, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 300, 'max_depth': 5, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 250, 'max_depth': 15, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 400, 'max_depth': 20, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 350, 'max_depth': 5, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 300, 'max_depth': 10, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 150, 'max_depth': 5, 'criterion': 'squared_error'},\n",
       "  {'n_estimators': 200, 'max_depth': 5, 'criterion': 'squared_error'}],\n",
       " 'split0_test_score': array([0.24158906, 0.26135035, 0.2485908 , 0.24879728, 0.24824529,\n",
       "        0.24502532, 0.24469537, 0.26594621, 0.27627463, 0.25110377,\n",
       "        0.27824885, 0.24107713, 0.36180345, 0.36104895, 0.25203345,\n",
       "        0.23635743, 0.36010607, 0.27118635, 0.35989455, 0.36145912]),\n",
       " 'split1_test_score': array([0.5954309 , 0.60664342, 0.58595091, 0.58082726, 0.59181105,\n",
       "        0.59276229, 0.5962174 , 0.60337335, 0.60251511, 0.58878676,\n",
       "        0.59802301, 0.59534743, 0.55738502, 0.56350165, 0.58617675,\n",
       "        0.59896754, 0.56113831, 0.6024267 , 0.55825658, 0.55455346]),\n",
       " 'split2_test_score': array([0.48385869, 0.50433857, 0.4738281 , 0.46910253, 0.46849813,\n",
       "        0.4662613 , 0.48647368, 0.50619019, 0.48408449, 0.46647685,\n",
       "        0.48150729, 0.48399585, 0.53175497, 0.55558523, 0.47645155,\n",
       "        0.48056387, 0.56247716, 0.49511163, 0.53857333, 0.53855123]),\n",
       " 'split3_test_score': array([0.7539589 , 0.7665993 , 0.75500282, 0.75096574, 0.74737101,\n",
       "        0.7487    , 0.75491856, 0.76554214, 0.75674764, 0.74980863,\n",
       "        0.76122183, 0.75416357, 0.73541528, 0.74168508, 0.7547575 ,\n",
       "        0.75427906, 0.74094865, 0.76636686, 0.72964727, 0.73434567]),\n",
       " 'split4_test_score': array([0.7280233 , 0.73170019, 0.72872614, 0.72373147, 0.72477102,\n",
       "        0.72474163, 0.72995072, 0.73050373, 0.72328887, 0.72979192,\n",
       "        0.73014221, 0.72823849, 0.70671277, 0.7046647 , 0.73081463,\n",
       "        0.72898298, 0.70575614, 0.73034142, 0.70075   , 0.7028111 ]),\n",
       " 'split5_test_score': array([0.64533575, 0.65537837, 0.6411404 , 0.64552258, 0.64520834,\n",
       "        0.64560931, 0.64565842, 0.655346  , 0.65618147, 0.63788432,\n",
       "        0.64887001, 0.64557205, 0.66356204, 0.66488625, 0.64041459,\n",
       "        0.64494123, 0.6640556 , 0.65429704, 0.66632129, 0.66405254]),\n",
       " 'split6_test_score': array([0.47753825, 0.48546522, 0.48190434, 0.44741945, 0.48051581,\n",
       "        0.4778707 , 0.48132983, 0.48371342, 0.48679968, 0.48943995,\n",
       "        0.49541875, 0.47772068, 0.47025766, 0.47070514, 0.4852563 ,\n",
       "        0.4777486 , 0.47278117, 0.483183  , 0.47322731, 0.47443821]),\n",
       " 'split7_test_score': array([0.64229982, 0.63162859, 0.64984148, 0.65833045, 0.6436982 ,\n",
       "        0.64586499, 0.64251877, 0.63399847, 0.63669587, 0.64277358,\n",
       "        0.63494495, 0.64222748, 0.58736636, 0.58578425, 0.6494311 ,\n",
       "        0.6393101 , 0.58190029, 0.63605246, 0.57997993, 0.58164279]),\n",
       " 'split8_test_score': array([0.7614106 , 0.77484136, 0.75932141, 0.74941643, 0.754856  ,\n",
       "        0.75176878, 0.76311123, 0.77650841, 0.77059624, 0.75734787,\n",
       "        0.7751405 , 0.76173701, 0.77853573, 0.77969663, 0.76095671,\n",
       "        0.76002362, 0.77931199, 0.7764534 , 0.77742131, 0.77827792]),\n",
       " 'split9_test_score': array([0.57342229, 0.5756088 , 0.57392534, 0.5823176 , 0.58705118,\n",
       "        0.58431144, 0.57563771, 0.57895076, 0.58705243, 0.58373921,\n",
       "        0.58717997, 0.574094  , 0.60231608, 0.60532639, 0.57560739,\n",
       "        0.57066275, 0.60080859, 0.58196968, 0.60283235, 0.60686468]),\n",
       " 'mean_test_score': array([0.59028676, 0.59935542, 0.58982317, 0.58564308, 0.5892026 ,\n",
       "        0.58829157, 0.59205117, 0.60000727, 0.59802364, 0.58971529,\n",
       "        0.59906974, 0.59041737, 0.59951094, 0.60328843, 0.59119   ,\n",
       "        0.58918372, 0.6029284 , 0.59973885, 0.59869039, 0.59969967]),\n",
       " 'std_test_score': array([0.15057196, 0.14741938, 0.14944974, 0.15108856, 0.14818543,\n",
       "        0.14920657, 0.14985759, 0.14634854, 0.14302438, 0.14779197,\n",
       "        0.14348319, 0.15074471, 0.12076702, 0.12032138, 0.14851504,\n",
       "        0.15190435, 0.12008381, 0.14599557, 0.11935878, 0.11974836]),\n",
       " 'rank_test_score': array([14,  7, 15, 20, 17, 19, 11,  3, 10, 16,  8, 13,  6,  1, 12, 18,  2,\n",
       "         4,  9,  5], dtype=int32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c9fb0",
   "metadata": {},
   "source": [
    "<span style='color:blue'> <span style=\"font-size:15px;\"> **Print the best hyperparameters**:</span> </span>\n",
    "\n",
    "Combination that gives **the highest accuracy (coefficient of determination) during the cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaf94b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'max_depth': 5, 'criterion': 'squared_error'}\n"
     ]
    }
   ],
   "source": [
    "best_parameters = rf_random.best_params_\n",
    "print(best_parameters) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ba508",
   "metadata": {},
   "source": [
    "Print the accuracy we get for the \n",
    "<span style='color:green'> <span style=\"font-size:15px;\"> **best combination**:</span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3641e5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of Determination for the Random Forest = 60.33\n"
     ]
    }
   ],
   "source": [
    "highest_accuracy = rf_random.best_score_ \n",
    "highest_accuracy = round(highest_accuracy,4)\n",
    "highest_accuracy = highest_accuracy*100\n",
    "print('Coefficient of Determination for the Random Forest =', highest_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad73a24f",
   "metadata": {},
   "source": [
    "<span style='color:green'> <span style=\"font-size:15px;\"> *Load the results to Pandas DataFrame*:</span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "094a6c6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.578447</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>350</td>\n",
       "      <td>20</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 350, 'max_depth': 20, 'criter...</td>\n",
       "      <td>0.241589</td>\n",
       "      <td>0.595431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753959</td>\n",
       "      <td>0.728023</td>\n",
       "      <td>0.645336</td>\n",
       "      <td>0.477538</td>\n",
       "      <td>0.642300</td>\n",
       "      <td>0.761411</td>\n",
       "      <td>0.573422</td>\n",
       "      <td>0.590287</td>\n",
       "      <td>0.150572</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571454</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.024772</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 10, 'criter...</td>\n",
       "      <td>0.261350</td>\n",
       "      <td>0.606643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766599</td>\n",
       "      <td>0.731700</td>\n",
       "      <td>0.655378</td>\n",
       "      <td>0.485465</td>\n",
       "      <td>0.631629</td>\n",
       "      <td>0.774841</td>\n",
       "      <td>0.575609</td>\n",
       "      <td>0.599355</td>\n",
       "      <td>0.147419</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.420216</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.017564</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>250</td>\n",
       "      <td>20</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 250, 'max_depth': 20, 'criter...</td>\n",
       "      <td>0.248591</td>\n",
       "      <td>0.585951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755003</td>\n",
       "      <td>0.728726</td>\n",
       "      <td>0.641140</td>\n",
       "      <td>0.481904</td>\n",
       "      <td>0.649841</td>\n",
       "      <td>0.759321</td>\n",
       "      <td>0.573925</td>\n",
       "      <td>0.589823</td>\n",
       "      <td>0.149450</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166751</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.007569</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 20, 'criter...</td>\n",
       "      <td>0.248797</td>\n",
       "      <td>0.580827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750966</td>\n",
       "      <td>0.723731</td>\n",
       "      <td>0.645523</td>\n",
       "      <td>0.447419</td>\n",
       "      <td>0.658330</td>\n",
       "      <td>0.749416</td>\n",
       "      <td>0.582318</td>\n",
       "      <td>0.585643</td>\n",
       "      <td>0.151089</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.242069</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.010415</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 15, 'criter...</td>\n",
       "      <td>0.248245</td>\n",
       "      <td>0.591811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747371</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.645208</td>\n",
       "      <td>0.480516</td>\n",
       "      <td>0.643698</td>\n",
       "      <td>0.754856</td>\n",
       "      <td>0.587051</td>\n",
       "      <td>0.589203</td>\n",
       "      <td>0.148185</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.248260</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.010598</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>150</td>\n",
       "      <td>25</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 25, 'criter...</td>\n",
       "      <td>0.245025</td>\n",
       "      <td>0.592762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748700</td>\n",
       "      <td>0.724742</td>\n",
       "      <td>0.645609</td>\n",
       "      <td>0.477871</td>\n",
       "      <td>0.645865</td>\n",
       "      <td>0.751769</td>\n",
       "      <td>0.584311</td>\n",
       "      <td>0.588292</td>\n",
       "      <td>0.149207</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.562666</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.023115</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>350</td>\n",
       "      <td>15</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 350, 'max_depth': 15, 'criter...</td>\n",
       "      <td>0.244695</td>\n",
       "      <td>0.596217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754919</td>\n",
       "      <td>0.729951</td>\n",
       "      <td>0.645658</td>\n",
       "      <td>0.481330</td>\n",
       "      <td>0.642519</td>\n",
       "      <td>0.763111</td>\n",
       "      <td>0.575638</td>\n",
       "      <td>0.592051</td>\n",
       "      <td>0.149858</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.499618</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.021997</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 350, 'max_depth': 10, 'criter...</td>\n",
       "      <td>0.265946</td>\n",
       "      <td>0.603373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765542</td>\n",
       "      <td>0.730504</td>\n",
       "      <td>0.655346</td>\n",
       "      <td>0.483713</td>\n",
       "      <td>0.633998</td>\n",
       "      <td>0.776508</td>\n",
       "      <td>0.578951</td>\n",
       "      <td>0.600007</td>\n",
       "      <td>0.146349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.214048</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.009823</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 10, 'criter...</td>\n",
       "      <td>0.276275</td>\n",
       "      <td>0.602515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756748</td>\n",
       "      <td>0.723289</td>\n",
       "      <td>0.656181</td>\n",
       "      <td>0.486800</td>\n",
       "      <td>0.636696</td>\n",
       "      <td>0.770596</td>\n",
       "      <td>0.587052</td>\n",
       "      <td>0.598024</td>\n",
       "      <td>0.143024</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.321241</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.013432</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>200</td>\n",
       "      <td>15</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 15, 'criter...</td>\n",
       "      <td>0.251104</td>\n",
       "      <td>0.588787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749809</td>\n",
       "      <td>0.729792</td>\n",
       "      <td>0.637884</td>\n",
       "      <td>0.489440</td>\n",
       "      <td>0.642774</td>\n",
       "      <td>0.757348</td>\n",
       "      <td>0.583739</td>\n",
       "      <td>0.589715</td>\n",
       "      <td>0.147792</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.284329</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 10, 'criter...</td>\n",
       "      <td>0.278249</td>\n",
       "      <td>0.598023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761222</td>\n",
       "      <td>0.730142</td>\n",
       "      <td>0.648870</td>\n",
       "      <td>0.495419</td>\n",
       "      <td>0.634945</td>\n",
       "      <td>0.775140</td>\n",
       "      <td>0.587180</td>\n",
       "      <td>0.599070</td>\n",
       "      <td>0.143483</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.583600</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.023976</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>350</td>\n",
       "      <td>25</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 350, 'max_depth': 25, 'criter...</td>\n",
       "      <td>0.241077</td>\n",
       "      <td>0.595347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754164</td>\n",
       "      <td>0.728238</td>\n",
       "      <td>0.645572</td>\n",
       "      <td>0.477721</td>\n",
       "      <td>0.642227</td>\n",
       "      <td>0.761737</td>\n",
       "      <td>0.574094</td>\n",
       "      <td>0.590417</td>\n",
       "      <td>0.150745</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.115545</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>0.361803</td>\n",
       "      <td>0.557385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735415</td>\n",
       "      <td>0.706713</td>\n",
       "      <td>0.663562</td>\n",
       "      <td>0.470258</td>\n",
       "      <td>0.587366</td>\n",
       "      <td>0.778536</td>\n",
       "      <td>0.602316</td>\n",
       "      <td>0.599511</td>\n",
       "      <td>0.120767</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.345442</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.016905</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>0.361049</td>\n",
       "      <td>0.563502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741685</td>\n",
       "      <td>0.704665</td>\n",
       "      <td>0.664886</td>\n",
       "      <td>0.470705</td>\n",
       "      <td>0.585784</td>\n",
       "      <td>0.779697</td>\n",
       "      <td>0.605326</td>\n",
       "      <td>0.603288</td>\n",
       "      <td>0.120321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.402036</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>250</td>\n",
       "      <td>15</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 250, 'max_depth': 15, 'criter...</td>\n",
       "      <td>0.252033</td>\n",
       "      <td>0.586177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754757</td>\n",
       "      <td>0.730815</td>\n",
       "      <td>0.640415</td>\n",
       "      <td>0.485256</td>\n",
       "      <td>0.649431</td>\n",
       "      <td>0.760957</td>\n",
       "      <td>0.575607</td>\n",
       "      <td>0.591190</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.657222</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.026485</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>400</td>\n",
       "      <td>20</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 20, 'criter...</td>\n",
       "      <td>0.236357</td>\n",
       "      <td>0.598968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754279</td>\n",
       "      <td>0.728983</td>\n",
       "      <td>0.644941</td>\n",
       "      <td>0.477749</td>\n",
       "      <td>0.639310</td>\n",
       "      <td>0.760024</td>\n",
       "      <td>0.570663</td>\n",
       "      <td>0.589184</td>\n",
       "      <td>0.151904</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.406636</td>\n",
       "      <td>0.010722</td>\n",
       "      <td>0.019679</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>350</td>\n",
       "      <td>5</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 350, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>0.360106</td>\n",
       "      <td>0.561138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740949</td>\n",
       "      <td>0.705756</td>\n",
       "      <td>0.664056</td>\n",
       "      <td>0.472781</td>\n",
       "      <td>0.581900</td>\n",
       "      <td>0.779312</td>\n",
       "      <td>0.600809</td>\n",
       "      <td>0.602928</td>\n",
       "      <td>0.120084</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.426380</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.018718</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 10, 'criter...</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.602427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766367</td>\n",
       "      <td>0.730341</td>\n",
       "      <td>0.654297</td>\n",
       "      <td>0.483183</td>\n",
       "      <td>0.636052</td>\n",
       "      <td>0.776453</td>\n",
       "      <td>0.581970</td>\n",
       "      <td>0.599739</td>\n",
       "      <td>0.145996</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.175477</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>0.359895</td>\n",
       "      <td>0.558257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729647</td>\n",
       "      <td>0.700750</td>\n",
       "      <td>0.666321</td>\n",
       "      <td>0.473227</td>\n",
       "      <td>0.579980</td>\n",
       "      <td>0.777421</td>\n",
       "      <td>0.602832</td>\n",
       "      <td>0.598690</td>\n",
       "      <td>0.119359</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.231941</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>0.361459</td>\n",
       "      <td>0.554553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734346</td>\n",
       "      <td>0.702811</td>\n",
       "      <td>0.664053</td>\n",
       "      <td>0.474438</td>\n",
       "      <td>0.581643</td>\n",
       "      <td>0.778278</td>\n",
       "      <td>0.606865</td>\n",
       "      <td>0.599700</td>\n",
       "      <td>0.119748</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.578447      0.004142         0.023363        0.000234   \n",
       "1        0.571454      0.006055         0.024772        0.000565   \n",
       "2        0.420216      0.011252         0.017564        0.001233   \n",
       "3        0.166751      0.001522         0.007569        0.000399   \n",
       "4        0.242069      0.002464         0.010415        0.000268   \n",
       "5        0.248260      0.001196         0.010598        0.000117   \n",
       "6        0.562666      0.002921         0.023115        0.000218   \n",
       "7        0.499618      0.008930         0.021997        0.001670   \n",
       "8        0.214048      0.001498         0.009823        0.000175   \n",
       "9        0.321241      0.002867         0.013432        0.000163   \n",
       "10       0.284329      0.001816         0.012786        0.000317   \n",
       "11       0.583600      0.012247         0.023976        0.001617   \n",
       "12       0.115545      0.000672         0.006438        0.000279   \n",
       "13       0.345442      0.003385         0.016905        0.000256   \n",
       "14       0.402036      0.002379         0.016594        0.000339   \n",
       "15       0.657222      0.003313         0.026485        0.000438   \n",
       "16       0.406636      0.010722         0.019679        0.000362   \n",
       "17       0.426380      0.002927         0.018718        0.000554   \n",
       "18       0.175477      0.004158         0.009073        0.000144   \n",
       "19       0.231941      0.001491         0.011780        0.000160   \n",
       "\n",
       "   param_n_estimators param_max_depth param_criterion  \\\n",
       "0                 350              20   squared_error   \n",
       "1                 400              10   squared_error   \n",
       "2                 250              20   squared_error   \n",
       "3                 100              20   squared_error   \n",
       "4                 150              15   squared_error   \n",
       "5                 150              25   squared_error   \n",
       "6                 350              15   squared_error   \n",
       "7                 350              10   squared_error   \n",
       "8                 150              10   squared_error   \n",
       "9                 200              15   squared_error   \n",
       "10                200              10   squared_error   \n",
       "11                350              25   squared_error   \n",
       "12                100               5   squared_error   \n",
       "13                300               5   squared_error   \n",
       "14                250              15   squared_error   \n",
       "15                400              20   squared_error   \n",
       "16                350               5   squared_error   \n",
       "17                300              10   squared_error   \n",
       "18                150               5   squared_error   \n",
       "19                200               5   squared_error   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'n_estimators': 350, 'max_depth': 20, 'criter...           0.241589   \n",
       "1   {'n_estimators': 400, 'max_depth': 10, 'criter...           0.261350   \n",
       "2   {'n_estimators': 250, 'max_depth': 20, 'criter...           0.248591   \n",
       "3   {'n_estimators': 100, 'max_depth': 20, 'criter...           0.248797   \n",
       "4   {'n_estimators': 150, 'max_depth': 15, 'criter...           0.248245   \n",
       "5   {'n_estimators': 150, 'max_depth': 25, 'criter...           0.245025   \n",
       "6   {'n_estimators': 350, 'max_depth': 15, 'criter...           0.244695   \n",
       "7   {'n_estimators': 350, 'max_depth': 10, 'criter...           0.265946   \n",
       "8   {'n_estimators': 150, 'max_depth': 10, 'criter...           0.276275   \n",
       "9   {'n_estimators': 200, 'max_depth': 15, 'criter...           0.251104   \n",
       "10  {'n_estimators': 200, 'max_depth': 10, 'criter...           0.278249   \n",
       "11  {'n_estimators': 350, 'max_depth': 25, 'criter...           0.241077   \n",
       "12  {'n_estimators': 100, 'max_depth': 5, 'criteri...           0.361803   \n",
       "13  {'n_estimators': 300, 'max_depth': 5, 'criteri...           0.361049   \n",
       "14  {'n_estimators': 250, 'max_depth': 15, 'criter...           0.252033   \n",
       "15  {'n_estimators': 400, 'max_depth': 20, 'criter...           0.236357   \n",
       "16  {'n_estimators': 350, 'max_depth': 5, 'criteri...           0.360106   \n",
       "17  {'n_estimators': 300, 'max_depth': 10, 'criter...           0.271186   \n",
       "18  {'n_estimators': 150, 'max_depth': 5, 'criteri...           0.359895   \n",
       "19  {'n_estimators': 200, 'max_depth': 5, 'criteri...           0.361459   \n",
       "\n",
       "    split1_test_score  ...  split3_test_score  split4_test_score  \\\n",
       "0            0.595431  ...           0.753959           0.728023   \n",
       "1            0.606643  ...           0.766599           0.731700   \n",
       "2            0.585951  ...           0.755003           0.728726   \n",
       "3            0.580827  ...           0.750966           0.723731   \n",
       "4            0.591811  ...           0.747371           0.724771   \n",
       "5            0.592762  ...           0.748700           0.724742   \n",
       "6            0.596217  ...           0.754919           0.729951   \n",
       "7            0.603373  ...           0.765542           0.730504   \n",
       "8            0.602515  ...           0.756748           0.723289   \n",
       "9            0.588787  ...           0.749809           0.729792   \n",
       "10           0.598023  ...           0.761222           0.730142   \n",
       "11           0.595347  ...           0.754164           0.728238   \n",
       "12           0.557385  ...           0.735415           0.706713   \n",
       "13           0.563502  ...           0.741685           0.704665   \n",
       "14           0.586177  ...           0.754757           0.730815   \n",
       "15           0.598968  ...           0.754279           0.728983   \n",
       "16           0.561138  ...           0.740949           0.705756   \n",
       "17           0.602427  ...           0.766367           0.730341   \n",
       "18           0.558257  ...           0.729647           0.700750   \n",
       "19           0.554553  ...           0.734346           0.702811   \n",
       "\n",
       "    split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0            0.645336           0.477538           0.642300   \n",
       "1            0.655378           0.485465           0.631629   \n",
       "2            0.641140           0.481904           0.649841   \n",
       "3            0.645523           0.447419           0.658330   \n",
       "4            0.645208           0.480516           0.643698   \n",
       "5            0.645609           0.477871           0.645865   \n",
       "6            0.645658           0.481330           0.642519   \n",
       "7            0.655346           0.483713           0.633998   \n",
       "8            0.656181           0.486800           0.636696   \n",
       "9            0.637884           0.489440           0.642774   \n",
       "10           0.648870           0.495419           0.634945   \n",
       "11           0.645572           0.477721           0.642227   \n",
       "12           0.663562           0.470258           0.587366   \n",
       "13           0.664886           0.470705           0.585784   \n",
       "14           0.640415           0.485256           0.649431   \n",
       "15           0.644941           0.477749           0.639310   \n",
       "16           0.664056           0.472781           0.581900   \n",
       "17           0.654297           0.483183           0.636052   \n",
       "18           0.666321           0.473227           0.579980   \n",
       "19           0.664053           0.474438           0.581643   \n",
       "\n",
       "    split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.761411           0.573422         0.590287        0.150572   \n",
       "1            0.774841           0.575609         0.599355        0.147419   \n",
       "2            0.759321           0.573925         0.589823        0.149450   \n",
       "3            0.749416           0.582318         0.585643        0.151089   \n",
       "4            0.754856           0.587051         0.589203        0.148185   \n",
       "5            0.751769           0.584311         0.588292        0.149207   \n",
       "6            0.763111           0.575638         0.592051        0.149858   \n",
       "7            0.776508           0.578951         0.600007        0.146349   \n",
       "8            0.770596           0.587052         0.598024        0.143024   \n",
       "9            0.757348           0.583739         0.589715        0.147792   \n",
       "10           0.775140           0.587180         0.599070        0.143483   \n",
       "11           0.761737           0.574094         0.590417        0.150745   \n",
       "12           0.778536           0.602316         0.599511        0.120767   \n",
       "13           0.779697           0.605326         0.603288        0.120321   \n",
       "14           0.760957           0.575607         0.591190        0.148515   \n",
       "15           0.760024           0.570663         0.589184        0.151904   \n",
       "16           0.779312           0.600809         0.602928        0.120084   \n",
       "17           0.776453           0.581970         0.599739        0.145996   \n",
       "18           0.777421           0.602832         0.598690        0.119359   \n",
       "19           0.778278           0.606865         0.599700        0.119748   \n",
       "\n",
       "    rank_test_score  \n",
       "0                14  \n",
       "1                 7  \n",
       "2                15  \n",
       "3                20  \n",
       "4                17  \n",
       "5                19  \n",
       "6                11  \n",
       "7                 3  \n",
       "8                10  \n",
       "9                16  \n",
       "10                8  \n",
       "11               13  \n",
       "12                6  \n",
       "13                1  \n",
       "14               12  \n",
       "15               18  \n",
       "16                2  \n",
       "17                4  \n",
       "18                9  \n",
       "19                5  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(rf_random.cv_results_) \n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480fa2a7",
   "metadata": {},
   "source": [
    "<span style='color:green'> <span style=\"font-size:15px;\"> *Define the columns of interest*:</span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64858d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>350</td>\n",
       "      <td>20</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 350, 'max_depth': 20, 'criter...</td>\n",
       "      <td>0.590287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 10, 'criter...</td>\n",
       "      <td>0.599355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250</td>\n",
       "      <td>20</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 250, 'max_depth': 20, 'criter...</td>\n",
       "      <td>0.589823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 20, 'criter...</td>\n",
       "      <td>0.585643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>15</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 15, 'criter...</td>\n",
       "      <td>0.589203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150</td>\n",
       "      <td>25</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 25, 'criter...</td>\n",
       "      <td>0.588292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>350</td>\n",
       "      <td>15</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 350, 'max_depth': 15, 'criter...</td>\n",
       "      <td>0.592051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>350</td>\n",
       "      <td>10</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 350, 'max_depth': 10, 'criter...</td>\n",
       "      <td>0.600007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150</td>\n",
       "      <td>10</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 10, 'criter...</td>\n",
       "      <td>0.598024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>15</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 15, 'criter...</td>\n",
       "      <td>0.589715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 10, 'criter...</td>\n",
       "      <td>0.599070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>350</td>\n",
       "      <td>25</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 350, 'max_depth': 25, 'criter...</td>\n",
       "      <td>0.590417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>0.599511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>0.603288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>250</td>\n",
       "      <td>15</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 250, 'max_depth': 15, 'criter...</td>\n",
       "      <td>0.591190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>400</td>\n",
       "      <td>20</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 20, 'criter...</td>\n",
       "      <td>0.589184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>350</td>\n",
       "      <td>5</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 350, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>0.602928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 300, 'max_depth': 10, 'criter...</td>\n",
       "      <td>0.599739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>150</td>\n",
       "      <td>5</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 150, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>0.598690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'criteri...</td>\n",
       "      <td>0.599700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_estimators param_max_depth param_criterion  \\\n",
       "0                 350              20   squared_error   \n",
       "1                 400              10   squared_error   \n",
       "2                 250              20   squared_error   \n",
       "3                 100              20   squared_error   \n",
       "4                 150              15   squared_error   \n",
       "5                 150              25   squared_error   \n",
       "6                 350              15   squared_error   \n",
       "7                 350              10   squared_error   \n",
       "8                 150              10   squared_error   \n",
       "9                 200              15   squared_error   \n",
       "10                200              10   squared_error   \n",
       "11                350              25   squared_error   \n",
       "12                100               5   squared_error   \n",
       "13                300               5   squared_error   \n",
       "14                250              15   squared_error   \n",
       "15                400              20   squared_error   \n",
       "16                350               5   squared_error   \n",
       "17                300              10   squared_error   \n",
       "18                150               5   squared_error   \n",
       "19                200               5   squared_error   \n",
       "\n",
       "                                               params  mean_test_score  \n",
       "0   {'n_estimators': 350, 'max_depth': 20, 'criter...         0.590287  \n",
       "1   {'n_estimators': 400, 'max_depth': 10, 'criter...         0.599355  \n",
       "2   {'n_estimators': 250, 'max_depth': 20, 'criter...         0.589823  \n",
       "3   {'n_estimators': 100, 'max_depth': 20, 'criter...         0.585643  \n",
       "4   {'n_estimators': 150, 'max_depth': 15, 'criter...         0.589203  \n",
       "5   {'n_estimators': 150, 'max_depth': 25, 'criter...         0.588292  \n",
       "6   {'n_estimators': 350, 'max_depth': 15, 'criter...         0.592051  \n",
       "7   {'n_estimators': 350, 'max_depth': 10, 'criter...         0.600007  \n",
       "8   {'n_estimators': 150, 'max_depth': 10, 'criter...         0.598024  \n",
       "9   {'n_estimators': 200, 'max_depth': 15, 'criter...         0.589715  \n",
       "10  {'n_estimators': 200, 'max_depth': 10, 'criter...         0.599070  \n",
       "11  {'n_estimators': 350, 'max_depth': 25, 'criter...         0.590417  \n",
       "12  {'n_estimators': 100, 'max_depth': 5, 'criteri...         0.599511  \n",
       "13  {'n_estimators': 300, 'max_depth': 5, 'criteri...         0.603288  \n",
       "14  {'n_estimators': 250, 'max_depth': 15, 'criter...         0.591190  \n",
       "15  {'n_estimators': 400, 'max_depth': 20, 'criter...         0.589184  \n",
       "16  {'n_estimators': 350, 'max_depth': 5, 'criteri...         0.602928  \n",
       "17  {'n_estimators': 300, 'max_depth': 10, 'criter...         0.599739  \n",
       "18  {'n_estimators': 150, 'max_depth': 5, 'criteri...         0.598690  \n",
       "19  {'n_estimators': 200, 'max_depth': 5, 'criteri...         0.599700  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_of_interest = results[['param_n_estimators','param_max_depth','param_criterion','params','mean_test_score']]\n",
    "results_of_interest.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f2ffd",
   "metadata": {},
   "source": [
    "======================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca641f",
   "metadata": {},
   "source": [
    "<span style='color:red'> <span style=\"font-size:15px;\"> \n",
    "**Gradient Boosting Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cb567e",
   "metadata": {},
   "source": [
    "We consider the following **hyperparameters**:\n",
    "\n",
    "* n_estimators = number of trees in the forest; **(Number of trees to be used)**\n",
    "* max_depth = the maximum depth of the tree; **(Maximum number of levels in tree)**\n",
    "* criterion = the function that measures the quality of the split; **(Criterion to split on)**\n",
    "* Learning rate \n",
    "\n",
    "\n",
    "<span style='color:blue'> <span style=\"font-size:15px;\"> **then Grid Creation**:</span> </span>  grid of Hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52dd8eb",
   "metadata": {},
   "source": [
    "GRADIENT BOOSTING Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d58b1053",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_n_estimators = [100, 150, 200, 250, 300, 350, 400]\n",
    "gb_max_depth = [5, 10, 15, 20, 25]\n",
    "gb_rate = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "gb_criterion = ['squared_error']                       # It is optional \n",
    "\n",
    "gb_grid = {'n_estimators': gb_n_estimators,\n",
    "           'max_depth': gb_max_depth,\n",
    "           'learning_rate': gb_rate,\n",
    "           'criterion': gb_criterion}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1802e",
   "metadata": {},
   "source": [
    "In the line below:\n",
    "\n",
    "the RandomizedSearchCV class in scikit-learn is used **to tune the hyperparameters of a RandomForestRegressor model**.\n",
    "\n",
    "* The first line of code creates a **RandomForestRegressor model** with a random state of 42. This ensures that the results of the model are reproducible.\n",
    "\n",
    "\n",
    "* The second line of code creates a **RandomizedSearchCV object**. This object will be used to search for the best hyperparameters for the RandomForestRegressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b3d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingRegressor(random_state=42) # Shuffle=True by default \n",
    "\n",
    "gb_random = RandomizedSearchCV(gb_model, gb_grid, n_iter=20, cv=10, random_state=42)\n",
    "\n",
    "gb_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d596fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_random.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753af1eb",
   "metadata": {},
   "source": [
    "<span style='color:blue'> <span style=\"font-size:15px;\"> **Print the best hyperparameters**:</span> </span>\n",
    "\n",
    "Combination that gives **the highest accuracy (coefficient of determination) during the cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ec595",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_parameters = gb_random.best_params_\n",
    "print(best_parameters)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2c1e6",
   "metadata": {},
   "source": [
    "Print the accuracy we get for the \n",
    "<span style='color:green'> <span style=\"font-size:15px;\"> **best combination**:</span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_accuracy = gb_random.best_score_\n",
    "highest_accuracy = round(highest_accuracy,3)\n",
    "highest_accuracy = highest_accuracy*100\n",
    "print('Coefficient of Determination for the Gradient Boosting =', highest_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4175c5d",
   "metadata": {},
   "source": [
    "<span style='color:green'> <span style=\"font-size:15px;\"> *Load the results to Pandas DataFrame*:</span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b1e50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the results to Pandas DataFrame \n",
    "results = pd.DataFrame(gb_random.cv_results_) \n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3a645",
   "metadata": {},
   "source": [
    "<span style='color:green'> <span style=\"font-size:15px;\"> *Define the columns of interest*:</span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889aa01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_of_interest = results[['param_n_estimators','param_max_depth','param_learning_rate','params','mean_test_score']]\n",
    "results_of_interest.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa653b",
   "metadata": {},
   "source": [
    "======================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd51a2f",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\">**Evaluation of the Tuned Models and Visualization of Results**</span> </span>\n",
    "\n",
    "We consider the Test Dataset or, also called, the Hold-Out Dataset (20% of the Original Dataset) and we perform the prediction on this Dataset which is the \"unseen\" Dataset.\n",
    "\n",
    "**rf_final_model**\n",
    "\n",
    "**gb_final_model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tuned Random Forest \n",
    "rf_final_model=RandomForestRegressor(n_estimators=150, max_depth=10, random_state=42, criterion = 'squared_error')\n",
    "# Create the tuned Gradient Boosting \n",
    "gb_final_model=GradientBoostingRegressor(n_estimators=250, learning_rate=0.3, max_depth=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045b6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the tuned Random Forest \n",
    "rf_final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f1f0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the tuned Gradient Boosting \n",
    "gb_final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac9770",
   "metadata": {},
   "source": [
    "There are ( X_train ), ( X_test ), ( y_train ), ( y_test )\n",
    "\n",
    "**Plotting ( X_test ) vs. ( y_pred_rf )**\n",
    "\n",
    "**Plotting ( X_test ) vs. ( y_pred_gb )**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc5227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on Test data (RF)\n",
    "y_pred_rf = rf_final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb437c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on Test data (GB)\n",
    "y_pred_gb = gb_final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339f04c",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\">**PLOTS**</span> </span>\n",
    "\n",
    "================\n",
    "\n",
    "plot (y_test, y_pred_rf)\n",
    "\n",
    "plot (y_test, y_pred_gb)\n",
    "\n",
    "================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3641350",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\">**Performance Regression/Evaluation Metrics**</span> </span>\n",
    "\n",
    "Beside the \"Accuracy score\" which, in this case, is the \"Coefficient of Determination (r2)\", we can assess the goodness of fit of the models with the following Regression Metrics, by considering only the Test Dataset:\n",
    "\n",
    "<span style='color:red'> <span style=\"font-size:15px;\"> **Random Forest Model**</span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc266003",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred_rf)\n",
    "r2 = round(r2,4)\n",
    "r2 = r2*100\n",
    "print(\"Coefficient of Determination:\", r2)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred_rf, squared = False) # By default squared is True. If True returns MSE value, if False returns RMSE value\n",
    "rmse = round(rmse,4)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_rf, squared = True)\n",
    "mse = round(mse,4)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "mae = round(mae,4)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e298a3d1",
   "metadata": {},
   "source": [
    "<span style='color:red'> <span style=\"font-size:15px;\"> **Gradient Boosting Model**</span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdfd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred_gb)\n",
    "r2 = round(r2,4)\n",
    "r2 = r2*100\n",
    "print(\"Coefficient of Determination:\", r2)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred_gb, squared = False) # By default squared is True. If True returns MSE value, if False returns RMSE value\n",
    "rmse = round(rmse,4)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_gb, squared = True)\n",
    "mse = round(mse,4)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred_gb)\n",
    "mae = round(mae,4)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d57bf61",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\">**Selection of the Best Model**</span> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56ac96",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\">**Feature Importance**</span> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2de4cc",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\">**Save and Load the Random Forest & Gradient Boosting Models**</span> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a25950b",
   "metadata": {},
   "source": [
    "save model and load them to use other data from other wells and reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle  # Library for save and load scikit-learn models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df880cf8",
   "metadata": {},
   "source": [
    "<span style='color:red'> <span style=\"font-size:15px;\"> **Random Forest Model**</span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file name. \".pickle\" as file extension. A pickle file is a binary file. \n",
    "filename = \"random_forest.pickle\"\n",
    "\n",
    "# Save Random Forest Model by means of \"pickle.dump\" function to store the object data to the file. \n",
    "# This function takes 2 arguments:\n",
    "# Object that you want to store.\n",
    "# File object you get by opening the desired file in write-binary (wb) mode.\n",
    "pickle.dump(rf_final_model, open(filename, \"wb\"))\n",
    "\n",
    "# Load Random Forest Model by means of the \"pickle.load\" function.\n",
    "# The primary argument of the function is the file object you get by opening the desired file in read-binary (rb) mode.\n",
    "random_forest_model_loaded = pickle.load(open(filename, \"rb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To print the trained and tuned random forest model \n",
    "print(random_forest_model_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ee7ba",
   "metadata": {},
   "source": [
    "<span style='color:red'> <span style=\"font-size:15px;\"> **Gradient Boosting Model**</span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afaee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file name. \".pickle\" as file extension. A pickle file is a binary file. \n",
    "filename = \"gradient_boosting.pickle\"\n",
    "\n",
    "# Save Random Forest Model by means of \"pickle.dump\" function to store the object data to the file. \n",
    "# This function takes 2 arguments:\n",
    "# Object that you want to store.\n",
    "# File object you get by opening the desired file in write-binary (wb) mode.\n",
    "pickle.dump(gb_final_model, open(filename, \"wb\"))\n",
    "\n",
    "# Load Random Forest Model by means of the \"pickle.load\" function.\n",
    "# The primary argument of the function is the file object you get by opening the desired file in read-binary (rb) mode.\n",
    "gradient_boosting_model_loaded = pickle.load(open(filename, \"rb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa62c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c9db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ff312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e809e249",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:15px;\"> **Loading entire dataset on the model**</span> </span>\n",
    "\n",
    "You can use the loaded model to compute predictions\n",
    "\n",
    "We perform the prediction on the entire original dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"GR\",\"NPHI\"] \n",
    "X = df[predictors]\n",
    "y = df[\"PEFZ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New prediction on the entire dataset\n",
    "y_predicted_rf = random_forest_model_loaded.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab29ce6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2bd446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49630659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106e6548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6351237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209d675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3476bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4742369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a85e84f5",
   "metadata": {},
   "source": [
    "<span style='color:red'> <span style=\"font-size:15px;\"> **Gradient Boosting Model**</span> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365bef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a54e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119d5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc83c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1d27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201bf0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bc121f6",
   "metadata": {},
   "source": [
    "<span style='color:blue'> <span style=\"font-size:15px;\"> the Random Forest</span> </span>\n",
    "and\n",
    "<span style='color:blue'> <span style=\"font-size:15px;\"> Gradient Boosting models </span> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81fb31",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddaad91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a49e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00819773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a19659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e209c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb54156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a0a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee412b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5133c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0027f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633a424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f8ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665723d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
