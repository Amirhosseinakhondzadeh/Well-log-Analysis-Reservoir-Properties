{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04ac8fdb",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:25px;\"> **Development of \"Machine Learning Models\"  (Workflow)**\n",
    "    \n",
    "In this Notebook, the machine learning model will be created and then the data from well-logs DLIS file [after preprocessing, sorting and finalizing the data] is loaded as input for Machine Learning model (ML); \n",
    "* Random Forest Regressor\n",
    "* Gradient Boosting Regressor\n",
    "    \n",
    "    \n",
    "For the prediction of petrophysical properties, such as porosity, permeability and water saturation, these two Regressor models **Random Forest Regressor** and **Gradient Boosting Regressor** are suitable.\n",
    "\n",
    "They are Ensemble Based Tree Methods; they are based on the generation of Decision Trees.\n",
    "\n",
    "We use Regression Models since we want to predict a continuous variable.\n",
    "\n",
    "**Advantages** of the 2 regression models, since they are based on Decision Trees:\n",
    "\n",
    "* They do not need the normalization or scaling of the original dataset;\n",
    "* They are not sensitive to outliers, thus, outliers detection and removal are not required.\n",
    "\n",
    "**==================================================================================================================**\n",
    "    \n",
    "In well-log machine learning models, the choice between regression and classification (Supervised ML) depends on the nature of the problem you are trying to solve and the type of data you have. Let's break down the reasons why regression is often preferred over classification in this context:\n",
    "\n",
    "**Continuous Output**: Well-log data often involves continuous measurements such as porosity, permeability, resistivity, and other geological properties. Regression is well-suited for predicting and modeling continuous numerical values. Classification, on the other hand, is typically used when the output is categorical or discrete, like classifying lithology or rock types.\n",
    "\n",
    "**Data Distribution**: Well-log data tends to have a wide range of continuous values. Using classification would require discretizing this data into bins or classes, which can lead to loss of information and potentially introduce biases. Regression models can capture the nuances and variations present in the continuous data more effectively.\n",
    "\n",
    "**Evaluation Metrics**: Regression models are evaluated using metrics such as mean squared error (MSE), root mean squared error (RMSE), or mean absolute error (MAE). These metrics are well-suited for measuring the accuracy of predictions involving continuous values. Classification models, on the other hand, use metrics like accuracy, precision, recall, and F1-score, which are designed for categorical predictions.\n",
    "\n",
    "**Feature Importance**: Well-log data analysis often involves understanding the relationships between different geological features and the target property. Regression models can provide insights into the quantitative impact of each feature on the predicted values, aiding in geological interpretation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2f6a2",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Importing Libraries, Regressors, and Required Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5974699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade scikit-learn==1.2.2\n",
    "%pip install --quiet qbstyles\n",
    "\n",
    "\n",
    "# Importing the dependencies\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches # To create a legend with a color box\n",
    "import pickle\n",
    "\n",
    "# Importing the models \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\"\"\"\n",
    "                                         \n",
    "\n",
    "from qbstyles import mpl_style\n",
    "mpl_style(dark=False) # Set light matplotlib style\n",
    "\n",
    "# train_test_split is a function \n",
    "# cross_val_score and KFold are functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold \n",
    "\n",
    "# Regression metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# The package \"Matplotlib Inline Back-end\" provides support for Matplotlib to display figures directly inline\n",
    "# \"svg\" stands for \"scalable vector graphic\". The plot can be scaled without compromising its quality\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae917b",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Loading datafile that has been extracted from DLIS or LAS file after (Sorting, Cleaning, preprocessing, choosing the logs based on need logically ...)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c42b2f",
   "metadata": {},
   "source": [
    "Load the **csv** well log data to Pandas DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "243aff34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>GR</th>\n",
       "      <th>RHGX_HILT</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>AT10</th>\n",
       "      <th>AT20</th>\n",
       "      <th>AT30</th>\n",
       "      <th>AT60</th>\n",
       "      <th>AT90</th>\n",
       "      <th>PEFZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3241.2432</td>\n",
       "      <td>43.603180</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3241.3955</td>\n",
       "      <td>43.603180</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3241.5480</td>\n",
       "      <td>31.196218</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3241.7004</td>\n",
       "      <td>22.927324</td>\n",
       "      <td>2.831039</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3241.8528</td>\n",
       "      <td>25.734980</td>\n",
       "      <td>2.832985</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>51.794643</td>\n",
       "      <td>61.238102</td>\n",
       "      <td>52.368523</td>\n",
       "      <td>47.517567</td>\n",
       "      <td>38.26941</td>\n",
       "      <td>3.912346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>3415.1316</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.834162</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.251309</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.902054</td>\n",
       "      <td>419.289830</td>\n",
       "      <td>207.16121</td>\n",
       "      <td>3.492837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>3415.2840</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.833239</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.248991</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.493515</td>\n",
       "      <td>412.861100</td>\n",
       "      <td>209.38712</td>\n",
       "      <td>3.481267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>3415.4365</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.832363</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.247348</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.377750</td>\n",
       "      <td>416.689060</td>\n",
       "      <td>214.43398</td>\n",
       "      <td>3.470307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>3415.5889</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.831719</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.247392</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.574510</td>\n",
       "      <td>427.813420</td>\n",
       "      <td>221.12366</td>\n",
       "      <td>3.467056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>3415.7412</td>\n",
       "      <td>219.444870</td>\n",
       "      <td>2.831719</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>6.245775</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>101.995930</td>\n",
       "      <td>442.204500</td>\n",
       "      <td>227.71360</td>\n",
       "      <td>3.467056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1146 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DEPTH          GR  RHGX_HILT      NPHI       AT10         AT20  \\\n",
       "0     3241.2432   43.603180   2.831039  0.011302  51.794643    61.238102   \n",
       "1     3241.3955   43.603180   2.831039  0.011302  51.794643    61.238102   \n",
       "2     3241.5480   31.196218   2.831039  0.011302  51.794643    61.238102   \n",
       "3     3241.7004   22.927324   2.831039  0.011413  51.794643    61.238102   \n",
       "4     3241.8528   25.734980   2.832985  0.011976  51.794643    61.238102   \n",
       "...         ...         ...        ...       ...        ...          ...   \n",
       "1141  3415.1316  219.444870   2.834162  0.091268   6.251309  1950.000000   \n",
       "1142  3415.2840  219.444870   2.833239  0.091268   6.248991  1950.000000   \n",
       "1143  3415.4365  219.444870   2.832363  0.091268   6.247348  1950.000000   \n",
       "1144  3415.5889  219.444870   2.831719  0.091268   6.247392  1950.000000   \n",
       "1145  3415.7412  219.444870   2.831719  0.091268   6.245775  1950.000000   \n",
       "\n",
       "            AT30        AT60       AT90      PEFZ  \n",
       "0      52.368523   47.517567   38.26941  3.912346  \n",
       "1      52.368523   47.517567   38.26941  3.912346  \n",
       "2      52.368523   47.517567   38.26941  3.912346  \n",
       "3      52.368523   47.517567   38.26941  3.912346  \n",
       "4      52.368523   47.517567   38.26941  3.912346  \n",
       "...          ...         ...        ...       ...  \n",
       "1141  101.902054  419.289830  207.16121  3.492837  \n",
       "1142  101.493515  412.861100  209.38712  3.481267  \n",
       "1143  101.377750  416.689060  214.43398  3.470307  \n",
       "1144  101.574510  427.813420  221.12366  3.467056  \n",
       "1145  101.995930  442.204500  227.71360  3.467056  \n",
       "\n",
       "[1146 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/amirhosseinakhondzadeh/CODE_WELLLOGS/Petrobras Well-log Analysis/Processed Data (out put of preprocessing == Input of ML)/df0_ML.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cb5a39",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Defining Predictor (X) and what will be predicted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c8be7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\"GR\",\"NPHI\"] \n",
    "X = df[predictors]\n",
    "y = df[\"PEFZ\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32c78a",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "    \n",
    "**Training & Test Well Log Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be65ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be0dc9b",
   "metadata": {},
   "source": [
    "* **Data Splitting Function**: We utilize the \"train_test_split\" function to perform the splitting of our data.\n",
    "\n",
    "\n",
    "* **Variables to Split**: The data we're working with consists of two main variables, denoted as X and y. These are the entities that we want to partition.\n",
    "\n",
    "\n",
    "* **Training Set Size**: Instead of specifying an exact training set size, we have the option to leave it as \"None.\" In this case, the function will automatically determine the training size based on the complement of the test size. The test size is set at 20%, meaning 80% will be allocated to the training set.\n",
    "\n",
    "\n",
    "* **Test Set Size**: We assign a test size of 20%, indicating that one-fifth of the entire dataset will be allocated for testing the model's performance.\n",
    "\n",
    "\n",
    "* **Shuffling Data**: The default behavior is to shuffle the data prior to splitting. This randomization helps in creating a balanced distribution between the training and test sets.\n",
    "\n",
    "\n",
    "* **Reproducibility with Random Seed**: For the sake of reproducibility across multiple runs of the function, we introduce an integer value known as the \"random state.\" Here, we've chosen the value 42. It's essential to set this only when shuffling is enabled.\n",
    "\n",
    "\n",
    "*In essence, we're utilizing the \"train_test_split\" function to divide our data into training and test portions. We provide our data variables X and y, and the function handles the allocation. The training size is determined as the complementary value to the test size, which is set at 20%. Shuffling the data ensures randomness, and to achieve consistent outcomes in different runs, we use a random state value of 42, applying it only when shuffling is activated.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d1158f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1146, 2) (1146,) (916, 2) (230, 2) (916,) (230,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e72907",
   "metadata": {},
   "source": [
    "<span style='color:gray'> <span style=\"font-size:20px;\"> \n",
    "**Cross-Validation: Enhancing Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6eb0b8",
   "metadata": {},
   "source": [
    "<span style='color:black'> <span style='font-size:14px;'> **Cross-validation is a technique used to evaluate the performance of a machine learning model. It works by dividing the training dataset into k subsets, called folds. The model is then trained on k-1 folds of the training dataset and evaluated on the remaining fold. This procedure is repeated k times, with each fold being used as the validation set once. The average accuracy of the model across all k folds is then used as an estimate of the model's overall performance.**</span></span>\n",
    "\n",
    "* It is proposed to use k-fold cross-validation to evaluate the performance of two models on the training dataset. This will help them to choose the model that is most likely to generalize well to unseen data.\n",
    "\n",
    "* The k-fold cross-validation step can be skipped, since it will be carried out again during the optimization process. However, it is still a good idea to perform k-fold cross-validation on the training dataset before starting the optimization process, as this will help to ensure that the optimization process is not converging to a local optimum.\n",
    "\n",
    "Here are some additional details about k-fold cross-validation:\n",
    "\n",
    "- The value of k is typically chosen to be between 5 and 10.\n",
    "- The folds should be created randomly, to avoid any bias in the results.\n",
    "- The model should be trained and evaluated on the same set of features for each fold.\n",
    "- The accuracy of the model is typically measured using a metric such as the coefficient of determination.\n",
    "\n",
    "\n",
    "K-fold cross-validation is a powerful technique for evaluating the performance of machine learning models. It is more reliable than simply training and evaluating the model on a single holdout dataset, as it helps to mitigate the effects of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236f1f37",
   "metadata": {},
   "source": [
    "\n",
    "<span style='color:blue'> <span style='font-size:14px;'> X </span></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b9ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabf283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e309f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df503b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb437c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95e790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
